---
title: Sizing Guidelines
---

<head>
    <meta name="title" content="Sizing Guidelines| Redpanda Docs"/>
    <meta name="description" content="How to size Redpanda clusters for low, medium, and high throughput use cases in your data center and in the cloud."/>
</head>

For best performance, size your Redpanda cluster to handle the volume of data being produced, replicated, and consumed. The following variables affect cluster sizing:

- MB/sec of data being produced and consumed (after compression, if applied)
- Topic replication factor
- Number of producers and consumers

Throughput and retention requirements can cause bottlenecks in the system. On an undersized cluster, clients could saturate the available network bandwidth, a disk could run out of IOPS and be unable to keep up with writes, or you could simply run out of disk space. On an oversized Redpanda cluster, you could overpay for unnecessary infrastructure. For detailed sizing on various throughput and retention scenarios, see [Sizing Use Cases](../../deployment/sizing-use-cases).

This topic describes sizing considerations. In general:
- 2:1 core-to-local-disk ratio for maximum I/O performance (preferably NVMe SSD)
- Minimum of 2GB memory for each core, but more memory is better
- Total network bandwidth needs to account for writes, replication, and reads
- Test with I3en (AWS), n2-standard (GCP), and lsv2 (Azure) cloud instance types
- Use Tiered Storage to unify historical and real-time data
- Run hardware and Redpanda benchmark tests to provide a performance baseline

## Sizing considerations

### Network

A basic Redpanda cluster can have three nodes, a topic with a single partition and a replication factor of three, and a single producer and consumer. For every 100 MB written to the partition’s leader, 200 MB is transmitted across the network to other nodes for replication, and 100 MB is transmitted to the consumer. In this case, producing 100 MB/sec equates to 400 MB/sec (3,200 Mbps) of network traffic. Even with the same amount of data produced, increasing the replication factor or the number of consumers increases bandwidth utilization.

It’s important to measure the network bandwidth between nodes, and between clients and nodes, to make sure that you’re getting the expected performance from the network. This is especially important for cloud deployments where network bandwidth is not always guaranteed. For example, AWS I3en instances only guarantee network bandwidth above a certain instance size (`i3en.6xlarge`). Below that size, network bandwidth is advertised as “up to 25 Gbps”. For this reason, soak test the network to understand how it behaves over longer periods of time. 

The following example uses [iPerf3](https://iperf.fr/) to test the network bandwidth between two Debian-based servers:

```bash
redpanda1:~$ sudo apt -y update; sudo apt -y install iperf3
redpanda1:~$ iperf3 -s
-----------------------------------------------------------
Server listening on 5201
-----------------------------------------------------------
redpanda2:~$ sudo apt update; sudo apt install iperf3
redpanda2:~$ iperf3 -c redpanda1 -p 5201 -t 300
Connecting to host redpanda1, port 5201
[ ID] Interval Transfer Bitrate Retr Cwnd
[ 5] 0.00-1.00 sec 1.11 GBytes 9.57 Gbits/sec 0 1.64 
MBytes
[ 5] 1.00-2.00 sec 1.11 GBytes 9.53 Gbits/sec 0 1.64 
MBytes
[ 5] 2.00-3.00 sec 1.11 GBytes 9.53 Gbits/sec 0 1.64 
MBytes
[ 5] 3.00-4.00 sec 1.11 GBytes 9.53 Gbits/sec 0 1.72 
MBytes
[ 5] 4.00-5.00 sec 1.11 GBytes 9.53 Gbits/sec 0 1.72 
MBytes
...
```

### CPU and memory

Topic partitions are the unit of parallelisation in Redpanda. Adding partitions is how you scale to meet workload demands. Redpanda is designed to scale up to utilize all available hardware and scale out to distribute performance across multiple nodes.

Redpanda implements a thread-per-core programming model through its use of the [Seastar](https://seastar.io/) library. This allows Redpanda to pin each of its application threads to a CPU core to avoid context switching and blocking, significantly improving processing performance and efficiency.

Redpanda can handle approximately one GB/sec of writes for each core, depending on the workload. Since NVMe disks can have a sustained write speed of over one GB/sec, it takes two cores to saturate a single NVMe disk. At higher throughput rates, a 2:1 core-to-disk ratio is important to avoid I/O bottlenecks, and a minimum of four cores is needed.

Redpanda is basically a distributed transaction log, with well-understood access patterns. It appends data to the end of log files, and sequentially reads data from log files. For this reason, Redpanda bypasses the Linux page cache and manages its own memory and disk I/O. This gives Redpanda complete control over the underlying hardware to optimize I/O performance, deliver predictable tail latencies, and minimize its memory footprint. A minimum of two GB of memory for each core is recommended, but more is better.

### Storage

Your best storage solution for your workload depends on your performance and data retention requirements. 

If high throughput and low latency is most important, then use locally-attached NVMe SSD disks. This is also a good option in the cloud. Just remember that local disks are ephemeral and data is wiped when an instance is restarted. An alternative in the cloud is to use SSD-backed remote storage to persist data between instance restarts. The hyper-clouds provide options for guaranteeing throughput and provisioned IOPS performance.

For example, AWS io2 volumes offer up to 64,000 IOPS and 1,000 MB/sec throughput with single-digit millisecond latency. This is an expensive option, so if you can trade performance for cost, then AWS gp3 volumes are a good alternative. GCP has comparable options with high-end Extreme persistent disks and the lesser SSD persistent disks. Likewise, Azure has Ultra, Premium, and Standard persistent disk options for choosing the right balance of performance versus cost.

Whichever option you choose, benchmark Redpanda’s underlying storage for read and write performance, at least from an I/O perspective. FIO is a good tool for replicating Redpanda’s sequential write pattern and load. The following example shows how to run FIO on a Debian-based server:

```bash
$ sudo apt -y update; sudo apt -y install fio
$ cd /var/lib/redpanda/data
$ sudo vim fio-seq-write.job
[global]
name=fio-seq-write
filename=fio-seq-write
rw=write
bs=16K
direct=1
numjobs=4
group_reporting
time_based
runtime=300
[file1]
size=10G
ioengine=libaio
iodepth=16
$ sudo fio fio-seq-write.job
```

Key performance metrics:
- IOPS = Input and output operations per second. IOPS represents how many sequential write operations per second the volume can handle.
- BW = Average bandwidth measured in MB per second. Bandwidth divided by the write block size (for example, bs=16K) is the IOPS.
- slat = Submission latency. The time in microseconds to submit the I/O to the kernel.
- clat = Completion latency. The time in microseconds after slat until the device has completed the I/O.
- lat = Overall latency in microseconds.
- clat percentiles = Completion tail latency. Pay particular attention to p90 and above. This is a good indication of whether the volume can deliver predictable, consistent performance.

### Data retention

Retention properties control how long messages are kept on disk before they're deleted or compacted. You can configure data retention until message age or aggregate message size in the topic is exceeded. Setting retention properties (at the topic level or the cluster level) is the best way to prevent old messages from accumulating on disk to the point that the disk becomes full. 

See also: [Configure message retention](../../deployment/disk-utilization/#configure-message-retention)

### Tiered Storage

With only local storage, data retention is limited to the provisioned capacity: you must provision more nodes to increase capacity. Adding nodes is expensive, because you’re forced to overprovision infrastructure regardless of whether you need the additional compute power. In most cases, this leads to underutilization and higher operational costs.

Redpanda Tiered Storage enables multi-tiered remote storage that archives log segments to S3-compatible object storage in near real time. Tiered Storage can be combined with local storage to provide infinite data retention and disaster recovery on a per-topic basis. Retention properties work the same for Tiered Storage topics and local storage topics. Data is retained in the cloud until it reaches the configured time or size limit. 

When Tiered Storage is enabled on a topic, it immediately copies closed log segments into the configured S3 bucket. The default log segment size is set to one GB, so by default, a topic’s object store lags approximately one GB behind the local copy. Lowering `segment.bytes` is one way to reduce this lag. This lets Redpanda archive smaller log segments more frequently, at the cost of increasing I/O and file count. You can also set an idle timeout to force Redpanda to periodically archive the contents of open log segments to object storage. This is useful if a topic’s write rate is low and log segments are kept open for long periods of time. Adjusting how much data the object store lags behind the local copy allows Redpanda to meet stricter recovery point in time objectives.

This is encapsulated in the Kafka API, so clients can continue to produce and consume data from Redpanda in the same way. Consumers that keep up with producers continue to read from local storage and are subject to the local data retention policy. Consumers that want to read from older offsets do so with the same consumer API, and Redpanda handles fetching the necessary log segments from object storage. 

See also: [Tiered Storage](../../data-management/tiered-storage/)

### Production settings

Before running performance benchmark testing, set Redpanda into production mode and run the auto-tuning tool on every node. This enables the necessary hardware optimizations and ensures that the kernel parameters are set correctly.

See also: [Set Redpanda production mode](../../deployment/production-deployment/#set-redpanda-production-mode)

### Open Messaging Benchmark

Performance benchmarking a distributed system like Redpanda requires careful orchestration, instrumentation, and measurement. Every cluster destined for production should be subject to performance benchmarking for validation and confidence in the setup.

The [Open Messaging Benchmark (OMB)](https://github.com/redpanda-data/openmessaging-benchmark) framework simplifies the process. OMB contains extensible tests that replicate realworld stress on a streaming platform to measure throughput and latency over given time periods. OMB can verify that a Redpanda cluster, deployed in your own data center or in the cloud, is sized appropriately for your use case. 

See also: [Redpanda Benchmarks](https://github.com/redpanda-data/openmessaging-benchmark/blob/main/driver-redpanda/README.md)

---
## Suggested reading

- [Thread-per-core buffer management for a modern Kafka-API storage system](https://redpanda.com/blog/tpc-buffers?utm_medium=content&utm_assetname=sizing_guide&utm_assettype=report&utm_source=gated_content&utm_campaign=tpc_architecture_blog)