---
title: Disk utilization
---

<head>
    <meta name="title" content="Disk utilization | Redpanda Docs"/>
    <meta name="description" content="If you exceed the low disk space threshold, Redpanda blocks writes to the local node from Kafka producers."/>
</head>

Redpanda blocks clients from producing when free disk space reaches a critically low level. This gives you time to take action. In addition, you can monitor your disk space, and you can configure retention and storage settings to ensure the production stability of the cluster. 

:::caution
When a Redpanda node runs out of disk space, it terminates. This impacts performance, with leader reassignment and then replication and rebalancing. If more nodes in the cluster fill up and terminate, traffic concentrates in fewer nodes, also impacting performance. You can use Continuous Data Balancing (/docs/core/cluster-administration/data-balancing) to automatically balance disk usage. 
:::

## Full disk handling

If you exceed your low disk space threshold, Redpanda blocks clients from producing. In that state, Redpanda returns errors to external writers, but it still allows internal write traffic, such as replication and rebalancing. 

The `storage_min_free_bytes` configuration field determines the threshold of free space, or hard limit, for this write rejection. 

You can also set a soft limit for a minimum free disk space _alert_. This soft limit generates an error message and affects the value of the `vectorized_storage_disk_free_space_alert` metric, which you can monitor for early warning. The alert works with the following configuration properties, which you can set on any data disk (one drive per node):

* `storage_space_alert_free_threshold_bytes` - Minimum free disk space allowed, in bytes.
* `storage_space_alert_free_threshold_percent` - Minimum free disk space allowed, in percentage of total available space for that drive.

When either the byte or percent threshold is exceeded, `vectorized_storage_disk_free_space_alert` changes value, and a storage space alert error message is written to the Redpanda service log. Note that the alert threshold can be set in bytes or percentage of total space. To disable one threshold in favor of the other, set it to zero. 

## Disk space monitoring

You can check your total disk size and free space by viewing the metrics: 
* `vectorized_storage_disk_total_bytes`
* `vectorized_storage_disk_free_bytes`

As part of its continuous disk space monitoring, Redpanda updates these disk usage statistics, including the value of its `storage_space_alert` field based on your full disk alert threshold. This field is exposed with the `vectorized_storage_disk_free_space_alert` metric:
* 0 = no alert
* 1 = low free space alert
* 2 = out of space (degraded, external writes are rejected)

Storage space metrics are refreshed as part of the health monitorâ€™s backend tick processing, which collects node health reports for all members of the cluster. This lets any node see the `storage_space_alert` value for all nodes in the cluster, updated at a frequency determined by the health monitor. 

## Retention

Retention refers to the conditions under which messages in a topic are retained on disk. When retention conditions are exceeded, cleanup occurs. You can configure retention settings so that cleanup occurs under the following conditions: 

* Message age is exceeded
* Aggregate message size in the topic is exceeded
* Either message age is exceeded or aggregate message size in the topic is exceeded

The following table shows retention properties. 
If a value isn't specified at the topic-level configuration, then the topic uses the value of the cluster configuration. 
Note that cluster configuration property names use snake-case, while topic-level configurations use dots.

| Type of retention | Cluster-level configuration | Topic-level configuration <br /> (overrides cluster configuration) |
| ---               | ---                                                |  ---                                 |
| Time-based        | `delete_retention_ms` <br /> Default - `604800000` | `retention.ms` <br /> No default     |
| Size-based        | `retention_bytes`  <br /> Default - `null`         | `retention.bytes`  <br /> No default |
| Segment size      | `log_segment_size`  <br /> Default - `1073741824`  | N/A                                  |

### Time-based retention

A message is deleted if its age exceeds the value specified in `delete_retention_ms` or `retention.ms`. 

To set retention time for a single topic, use `retention.ms`, which overrides `delete_retention_ms`. If `retention.ms` is not set at the topic-level, the topic uses the `delete_retention_ms` value.

* `delete_retention_ms` - Cluster-level setting that specifies how long a message stays on disk before it's deleted. 
  
    To minimize the likelihood of out-of-disk outages, set `delete_retention_ms` to `86400000`, which is one day. The default value is `604800000`, which is one week.

* `retention.ms` - Topic-level setting that specifies how long a message stays on disk before it's deleted. This overrides the `delete_retention_ms` for the topic. 
  
  To minimize the likelihood of out-of-disk outages, set `retention.ms` to `86400000`. There is no default value, but if `retention.ms` is not set at the topic-level, the topic uses the `delete_retention_ms` value. 
  
  To set `retention.ms`, run: 

  ```bash
  rpk topic alter-config <topic> --set retention.ms=<retention_time>
  ```

:::caution 
Do not set `delete_retention_ms` to `-1` unless you're using <a href="https://docs.redpanda.com/docs/core/data-management/tiered-storage#remote-write" target="_self">remote write with Tiered Storage</a> to upload segments to remote storage. Setting it to `-1` configures indefinite retention, which can result in an out-of-disk outage. 
:::

### Size-based retention

A message is deleted if the size of the partition in which it is contained reaches the value specified in `retention_bytes` or `retention.bytes`. 

When a partition reaches the `retention_bytes` size, the oldest messages in the partition are deleted. To set retention size for a single topic, use `retention.bytes`, which overrides `retention_bytes`. If `retention.bytes` is not set at the topic-level, the topic uses `retention_bytes`.

* `retention_bytes` - Cluster-level property that specifies the maximum size of a partition. 

  Set this to a value that is lower than the disk capacity, or a fraction of the disk capacity based on the number of partitions per topic. For example, if you have one partition, `retention_bytes` can be 80% of the disk size. If you have 10 partitions, it can be 80% of the disk size divided by 10. The default value is `null`, which means that retention based on topic size is disabled.
  
  To set `retention_bytes`, run:
  
  ```bash
  rpk cluster config set retention_bytes <retention_size>
  ```

* `retention.bytes` - Topic-level setting that specifies the maximum size of a partition. 
 
  This setting overrides `retention_bytes` for the topic. There is no default value. When `retention.bytes` is not set at the topic-level, the topic uses `retention_bytes`. 

  To set `retention.bytes`, run:

  ```bash
  rpk topic alter-config <topic> --set retention.bytes=<retention_size>
  ```

## Segment size

The `log_segment_size` property specifies the size of each log segment.

To set `log_segment_size`, run:

```bash
rpk cluster config set log_segment_size <segment_size>
```

If you know which topics will receive more data, it's best to specify the size for each topic. 

To configure log segment size on a topic, run: 

```bash
rpk topic alter-config <topic> --set segment.bytes=<segment_size>
```

Keep in mind that very large segments prevent compaction, and very small segments increase the risk of encountering resource limits. To calculate an upper limit on segment size, you can divide the disk size by the number of partitions. For example, if you have a 128GB disk and 1000 partitions, the upper limit of the segment size would be `134217728`. Default is `1073741824`. 

For details about how to modify cluster configuration properties, see [Cluster configuration](/docs/core/cluster-administration/cluster-property-configuration). 

## Ballast file

You can create a ballast file to act as a buffer against an out-of-disk outage. The ballast file is an empty file that takes up disk space. If Redpanda runs out of disk space and becomes unavailable, you can delete the ballast file, which clears up some disk space and gives you time to delete topics or records and change your retention settings. Deletion of the ballast file is an emergency last resort.

To enable ballast file creation, set the following properties in the `redpanda.yaml` file: 

```yaml
tune_ballast_file: true
ballast_file_path: "/var/lib/redpanda/data/ballast"
ballast_file_size: "1GiB"
```

where: 
* `tune_ballast_file` - Set to `true` to enable ballast file creation. Default is `false`. 

* `ballast_file_path` - You can change the location of the ballast file, but it must be on the same mount point as the Redpanda data directory. Default is `/var/lib/redpanda/data/ballast`.

* `ballast_file_size` - Increase the ballast file size if it is a very high-throughput cluster, or decrease the ballast file size if you have very little storage space. The ballast file should be large enough to give you enough time to delete data and configure retention settings if Redpanda crashes, but small enough that you don't waste disk space. In general, set this to approximately 10 times the size of the largest segment, to have enough space to compact that topic. Default is `1GiB`. 